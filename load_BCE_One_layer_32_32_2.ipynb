{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87e1e8c8-fe88-4bc6-96f5-71c5476d6472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def spikes_between(arr, start, end):\n",
    "    return arr[np.where((start<=arr) & (arr<end))[0]]\n",
    "\n",
    "# def spikes_between(arr, start, end):\n",
    "#     return arr[np.where((start<=arr) & (arr<end))[0]]#arr[np.where(start<=arr)][np.where(arr[np.where(start<=arr)]<end)]\n",
    "# def count_between(arr, start, end):\n",
    "#     # print(type(arr))\n",
    "#     return len(np.where((start<=arr) & (arr<end))[0])#<end][np.where(arr[np.where(start<=arr)]<end)])\n",
    "def between(arr, start, end):\n",
    "    return arr[np.where(start<=arr)][np.where(arr[np.where(start<=arr)]<end)]\n",
    "def count_between(arr, start, end):\n",
    "    return len(arr[np.where(start<=arr)][np.where(arr[np.where(start<=arr)]<end)])\n",
    "\n",
    "\n",
    "def count_output_spikes_per_inputs(spikeTrain, number_of_input_data ,total_synaptic_delay = 0, timesteps =1, number_of_steps = 10, inputs_interval = 0, offset = 0):\n",
    "    # All the times must be in using dimension: uSecond or ... considering the `timestamp_coefficient` which is used in FPGA_Pop_SSA\n",
    "    data_length = timesteps*number_of_steps\n",
    "    start_base = data_length+offset+total_synaptic_delay+inputs_interval\n",
    "    s=[]\n",
    "    e=[]\n",
    "    s.append(0)\n",
    "    e.append(data_length+offset+inputs_interval//2+total_synaptic_delay)\n",
    "#     print(f'Strat: {s[0]}==> end: {e[0]}')\n",
    "\n",
    "    for i in range(1, number_of_input_data):\n",
    "        # s.append(i*data_length+offset+i*(inputs_interval)+total_synaptic_delay)\n",
    "        # e.append((i+1)*data_length+offset+(i+1)*(inputs_interval)+total_synaptic_delay)\n",
    "        s.append(e[i-1])\n",
    "        e.append(s[i]+data_length+inputs_interval)\n",
    "#         print(f'Strat: {s[i]}==> end: {e[i]}')\n",
    "    \n",
    "    n_output_neurons = len(spikeTrain)\n",
    "    print(n_output_neurons)\n",
    "    n_spikes_per_input_as_output = torch.zeros(n_output_neurons, number_of_input_data)\n",
    "    for i in range(number_of_input_data):\n",
    "        for j in range(n_output_neurons):\n",
    "            # print(spikeTrain[j])\n",
    "            # print(s[i], e[i])\n",
    "            # print(len(spikes_between(np.array(spikeTrain[j]), s[i], e[i])))\n",
    "            n_spikes_per_input_as_output[j, i]=count_between(np.array(spikeTrain[j]), s[i], e[i]) #len(spikes_between(np.array(spikeTrain[j]), s[i], e[i]))\n",
    "            # break\n",
    "    output_spike_count_matrix = n_spikes_per_input_as_output\n",
    "    return output_spike_count_matrix # retruns a matrix=> one row per output, each column shows the number of spikes caused per input \n",
    "\n",
    "def maxSpike_accuracy(true_labels, output_spike_count_matrix):\n",
    "\n",
    "    print(f'n_spikes_per_input_as_output = {output_spike_count_matrix}')\n",
    "    print(torch.argmax(output_spike_count_matrix,0))\n",
    "    print(true_labels)\n",
    "\n",
    "    print(torch.sum(torch.argmax(output_spike_count_matrix,0) == torch.tensor(true_labels)))\n",
    "    _, predicted = torch.max(output_spike_count_matrix, 0)\n",
    "    n_correct = (predicted == torch.tensor(targets[:n_input_samples])).sum().item()\n",
    "    print(n_correct)\n",
    "\n",
    "\n",
    "\n",
    "    acc = 100.0 * n_correct / n_input_samples\n",
    "    print(f'Accuracy of the network on the {n_input_samples} test images: {acc} %')\n",
    "    return\n",
    "\n",
    "\n",
    "def FPGA_Pop_SSA(dataLoader, input_size = [128, 128, 2], timesteps =1, number_of_steps = 10, inputs_interval = 0, offset = 0, timestamp_coefficient = 1000): \n",
    "    # timestamp_coefficient = 1000, for nSec to uSec and etc.\n",
    "    # Here since the input data is from the DVS sensor and it's already timed (timestamps), thus we don't need to set the timesteo and number of steps\n",
    "    # input_size is the sensor size\n",
    "\n",
    "    spikes_time_source_array=[[] for _ in range(np.prod(input_size))]\n",
    "    current_time = offset\n",
    "    targets = []\n",
    "    data_as_list = []\n",
    "    for data, target in dataLoader:\n",
    "        \n",
    "        targets.append(target)\n",
    "        data = data.squeeze(0)\n",
    "        data_as_list.append(data)\n",
    "        # data[:,2]+= inputs_interval\n",
    "        if len(data)>0:\n",
    "            pre_timestamp = data[0,2].item()#np.ceil(data[0,2].item()/timestamp_coefficient).astype(np.int32)#data[0,2]#np.ceil(data[0,2].item()//timestamp_coefficient).astype(np.int32)\n",
    "            spikes_time_source_array[((data[0,1] << 7) + (data[0,3] << 14)   + (data[0,0])).to(int)].append(current_time)#np.ceil(data[0,2].item()//timestamp_coefficient).astype(np.int32))\n",
    "            for e in data[1:]:\n",
    "                post_timestamp = e[2].item()#np.ceil(e[2].item()/timestamp_coefficient).astype(np.int32)#e[2].item()#np.ceil(e[2].item()//timestamp_coefficient).astype(np.int32)\n",
    "                time_gap = np.ceil((post_timestamp - pre_timestamp)/timestamp_coefficient).astype(np.int32)\n",
    "                current_time +=time_gap\n",
    "                spikes_time_source_array[((e[1] << 7) + (e[3] << 14)   + (e[0])).to(int)].append(current_time)\n",
    "                pre_timestamp = post_timestamp\n",
    "                # current_time+=event_interval\n",
    "            current_time+=inputs_interval\n",
    "\n",
    "    return spikes_time_source_array, data_as_list, targets, current_time\n",
    "\n",
    "def FPGA_Pop_SSA_2(dataLoader, input_size = [128, 128, 2], timesteps =1, number_of_steps = 10, inputs_interval = 0, offset = 0):#, timestamp_coefficient = 1000): \n",
    "    # timestamp_coefficient = 1000, for nSec to uSec and etc.\n",
    "    # Here since the input data is from the DVS sensor and it's already timed (timestamps), thus we don't need to set the timesteo and number of steps\n",
    "    # But- they are from different files and the timestamps are not ordered, so the only thing to keep the temporal aspect of the event is to keep inter_spikes times (time_gap parameter used for)\n",
    "    # input_size is the sensor size\n",
    "\n",
    "    spikes_time_source_array=[[] for _ in range(np.prod(input_size))]\n",
    "    current_time = offset\n",
    "    targets = []\n",
    "    data_as_list = []\n",
    "    for data, target in dataLoader:\n",
    "        \n",
    "        targets.append(target)\n",
    "        data = data.squeeze(0)\n",
    "        data_as_list.append(data)\n",
    "        # data[:,2]+= inputs_interval\n",
    "        if len(data)>0:\n",
    "            pre_timestamp = data[0,2].item()#np.ceil(data[0,2].item()/timestamp_coefficient).astype(np.int32)#data[0,2]#np.ceil(data[0,2].item()//timestamp_coefficient).astype(np.int32)\n",
    "            spikes_time_source_array[((data[0,1] << 7) + (data[0,3] << 14)   + (data[0,0])).to(int)].append(current_time)#np.ceil(data[0,2].item()//timestamp_coefficient).astype(np.int32))\n",
    "            for e in data[1:]:\n",
    "                post_timestamp = e[2].item()#np.ceil(e[2].item()/timestamp_coefficient).astype(np.int32)#e[2].item()#np.ceil(e[2].item()//timestamp_coefficient).astype(np.int32)\n",
    "                time_gap = post_timestamp - pre_timestamp\n",
    "                current_time +=time_gap\n",
    "                spikes_time_source_array[((e[1] << 7) + (e[3] << 14)   + (e[0])).to(int)].append(current_time)\n",
    "                pre_timestamp = post_timestamp\n",
    "                # current_time+=event_interval\n",
    "            current_time+=inputs_interval\n",
    "\n",
    "    return spikes_time_source_array, data_as_list, targets, current_time\n",
    "\n",
    "\n",
    "def plot_spikes_count_as_frame(output_spike_count_matrix, index, data_as_list = None):\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig.add_subplot(1,2,1)\n",
    "    dim = int(math.sqrt(len(output_spike_count_matrix)/2))\n",
    "    plt.imshow(output_spike_count_matrix[:,index].reshape(2, dim,dim)[1].T)#, cmap='jet')#(dim,dim, 2)[:,:,0])\n",
    "    fig.add_subplot(1,2,2)\n",
    "    plt.imshow(output_spike_count_matrix[:,index].reshape(2, dim,dim)[0].T)#, cmap='jet')#(128,128, 2)[:,:,1])\n",
    "        \n",
    "    if data_as_list!=None:\n",
    "        fig = plt.figure()\n",
    "        d = data_as_list[index]\n",
    "        frame = torch.zeros(2, 128, 128)\n",
    "        pos = d[torch.where(d[:,3] ==1)]\n",
    "        neg = d[torch.where(d[:,3] ==0)]\n",
    "        frame[0, pos[:,0].to(int), pos[:,1].to(int)] = 1\n",
    "        frame[1, neg[:,0].to(int), neg[:,1].to(int)] = 1\n",
    "        fig.add_subplot(1,2,1)\n",
    "        plt.imshow(frame[0])\n",
    "        fig.add_subplot(1,2,2)\n",
    "        plt.imshow(frame[1])    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d3198e-4726-401a-84f8-1f00091496ae",
   "metadata": {},
   "source": [
    "## Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c7860d7-8ea5-4bbb-9299-9ed0a6d4ca2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "same_size_classes: False\n",
      "n_total_samples_in_cls 1: {'sea': 288, 'gro': 279}\n",
      "n_total_samples_in_cls 2: {'sea': 288, 'gro': 279}\n",
      "567\n",
      "{'sea': 288, 'gro': 279}\n",
      "567\n",
      "fractions: [425, 142]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import my_data_utils\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "\n",
    "# dataset_all = my_data_utils.AprovisDataSet(src_path='Data', same_size_classes=False,  verbose=False, temporal_scale_factor=1000, time_window=1e2)# temporal_scale_factor = 1000: uSec to mSec, time_window = 100: each 100 mSec is one sample\n",
    "# PacmanTooBigToPlace: SpikeSourceArrayVertex_1 will not fit on any possible Chip \n",
    "# the reason is that [SpikeSourceArrayVertex_1(0:32767)] requires 543207176.0 bytes but a Chip only has 123469792 bytes Lowering max_core_per_chip may resolve this.\n",
    "\n",
    "dataset_all = my_data_utils.AprovisDataSet(src_path='Data', same_size_classes=False,  verbose=False, temporal_scale_factor=1000, time_window=1e3)# temporal_scale_factor = 1000: uSec to mSec, time_window = 1000: each 1000 mSec is one sample\n",
    "                                                                                                                                                  # # temporal_scale_factor = 1: uSec, time_window = 1e6: each 1e6 uSec is one sample\n",
    "\n",
    "print(len(dataset_all))                                                                                                                        \n",
    "print(dataset_all.n_total_samples_in_cls)\n",
    "\n",
    "def split_train(full_dataset, train_fraction,transform):\n",
    "    # print(train_data_folder)\n",
    "    # data_train = full_dataset#ImageFolder(train_data_folder, transform)\n",
    "    fractions = [int(train_fraction*len(full_dataset)),len(full_dataset)-int(train_fraction*len(full_dataset))]\n",
    "    print(len(full_dataset))\n",
    "    print(f'fractions: {fractions}')\n",
    "    train, test = random_split(full_dataset, fractions, generator=torch.Generator().manual_seed(42))\n",
    "    return train, test\n",
    "\n",
    "train_set, test_set = split_train(full_dataset = dataset_all, train_fraction=.75, transform=None)\n",
    "batch_size = 1\n",
    "trainloader = DataLoader(train_set, batch_size=batch_size, shuffle=False)\n",
    "testloader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fbf059-8777-429b-ac67-bb25fb4e5bbe",
   "metadata": {},
   "source": [
    "## Using the same connection list that is used for connecting the FPGA Population to the first population (https://github.com/ntouev/ev_snn_percept/blob/main/spinnaker/scripts/rt-online_ht_snn.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37b3a6a7-0d43-4ef3-8085-8cb61e15b373",
   "metadata": {},
   "outputs": [],
   "source": [
    "RETINA_DIM = 128\n",
    "# xy dimension is RETINA_DIM/SCALEDOWN x RETINA_DIM/SCALEDOWN\n",
    "SCALEDOWN = 4\n",
    "# planar dimension is THETA_NUM x R_NUM\n",
    "THETA_NUM = 90\n",
    "R_NUM = 60   \n",
    "\n",
    "################################################\n",
    "\n",
    "X_NUM = round(RETINA_DIM/SCALEDOWN)\n",
    "Y_NUM = round(RETINA_DIM/SCALEDOWN)\n",
    "P_NUM = 2\n",
    "\n",
    "connections_ssa_xy = []\n",
    "for ret_p in range(P_NUM):\n",
    "    for ret_y in range(RETINA_DIM):\n",
    "        for ret_x in range(RETINA_DIM):\n",
    "#             if (ret_x >= L) and (ret_x <= RETINA_DIM - L - 1):    \n",
    "#                 ssa_xy_weight_mod = SSA_XY_WEIGHT * G\n",
    "#             else:\n",
    "#                 ssa_xy_weight_mod = SSA_XY_WEIGHT\n",
    "\n",
    "            tup = (ret_x + RETINA_DIM*ret_y + RETINA_DIM*RETINA_DIM*ret_p, \n",
    "                   ret_x//SCALEDOWN + X_NUM*(ret_y//SCALEDOWN) + X_NUM*Y_NUM*ret_p,\n",
    "                   10,#ssa_xy_weight_mod,\n",
    "                   1)#SSA_XY_DELAY) \n",
    "            connections_ssa_xy.append(tup)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d0e313-c210-48fc-9e55-dfdb1ae6c80a",
   "metadata": {},
   "source": [
    "## Converting the dataLoader into SpikeSourceArray: It must be like what we will have from the `FPGA population` (DVS inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea62521b-fd58-4a57-8e35-e867cf95a5f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141364"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SSA_as_output_for_test, data_as_list, targets, time = FPGA_Pop_SSA_2(testloader, [128, 128, 2], inputs_interval= 0)# inputs_interval= 0 timestep (here is mSce): to have the consider as a stream\n",
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d80cbb2-159c-41c6-b89e-2f27170889bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-03 10:13:53 INFO: Read configs files: /home/bbpnrsoa/sPyNNakerGit/SpiNNUtils/spinn_utilities/spinn_utilities.cfg, /home/bbpnrsoa/sPyNNakerGit/SpiNNMachine/spinn_machine/spinn_machine.cfg, /home/bbpnrsoa/sPyNNakerGit/PACMAN/pacman/pacman.cfg, /home/bbpnrsoa/sPyNNakerGit/SpiNNMan/spinnman/spinnman.cfg, /home/bbpnrsoa/sPyNNakerGit/SpiNNFrontEndCommon/spinn_front_end_common/interface/spinnaker.cfg, /home/bbpnrsoa/sPyNNakerGit/sPyNNaker/spynnaker/pyNN/spynnaker.cfg, /home/bbpnrsoa/.spynnaker.cfg\n",
      "2023-07-03 10:13:53 INFO: Will search these locations for binaries: /home/bbpnrsoa/sPyNNakerGit/sPyNNaker/spynnaker/pyNN/model_binaries : /home/bbpnrsoa/sPyNNakerGit/SpiNNFrontEndCommon/spinn_front_end_common/common_model_binaries\n",
      "2023-07-03 10:13:53 INFO: Setting hardware timestep as 1000 microseconds based on simulation time step of 1000 and timescale factor of 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/bbpnrsoa/sPyNNakerGit/SpiNNUtils/spinn_utilities/spinn_utilities.cfg', '/home/bbpnrsoa/sPyNNakerGit/SpiNNMachine/spinn_machine/spinn_machine.cfg', '/home/bbpnrsoa/sPyNNakerGit/PACMAN/pacman/pacman.cfg', '/home/bbpnrsoa/sPyNNakerGit/SpiNNMan/spinnman/spinnman.cfg', '/home/bbpnrsoa/sPyNNakerGit/SpiNNFrontEndCommon/spinn_front_end_common/interface/spinnaker.cfg', '/home/bbpnrsoa/sPyNNakerGit/sPyNNaker/spynnaker/pyNN/spynnaker.cfg', '/home/bbpnrsoa/.spynnaker.cfg']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-03 10:13:53 WARNING: Danger of SpikeSourceArray sending too many spikes at the same time. For example at time 2149, 172 spikes will be sent\n",
      "2023-07-03 10:13:53 INFO: Starting execution process\n",
      "2023-07-03 10:13:53 INFO: Simulating for 141364 1.0 ms timesteps using a hardware timestep of 1000 us\n",
      "2023-07-03 10:13:54 INFO: SpYNNakerNeuronGraphNetworkSpecificationReport skipped as cfg Reports:write_network_graph is False\n",
      "2023-07-03 10:13:54 INFO: Network Specification report took 0:00:00.000500 \n",
      "2023-07-03 10:13:54 INFO: Splitter reset took 0:00:00.000012 \n",
      "Adding Splitter selectors where appropriate\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:13:54 INFO: Spynnaker splitter selector took 0:00:00.012745 \n",
      "Adding delay extensions as required\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:13:54 INFO: DelaySupportAdder took 0:00:00.012542 \n",
      "Partitioning Graph\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:13:54 INFO: Splitter partitioner took 0:00:00.734959 \n",
      "2023-07-03 10:13:54 INFO: 0.02 Boards Required for 1 chips\n",
      "2023-07-03 10:13:54 INFO: Requesting job with 1 boards\n",
      "Created spalloc job 7303970\n",
      "2023-07-03 10:13:54 INFO: Created spalloc job 7303970\n",
      "Waiting for board power commands to complete.\n",
      "2023-07-03 10:13:55 INFO: Waiting for board power commands to complete.\n",
      "2023-07-03 10:14:03 INFO: SpallocAllocator took 0:00:08.952063 \n",
      "2023-07-03 10:14:03 INFO: Creating transceiver for 10.11.193.1\n",
      "2023-07-03 10:14:03 INFO: Working out if machine is booted\n",
      "2023-07-03 10:14:07 INFO: Attempting to boot machine\n",
      "2023-07-03 10:14:13 INFO: Found board with version [Version: SC&MP 3.4.2 at SpiNNaker:0:0:0 (built Fri Jun 10 17:21:19 2022)]\n",
      "2023-07-03 10:14:13 INFO: Machine communication successful\n",
      "2023-07-03 10:14:13 INFO: 10.11.193.1\n",
      "2023-07-03 10:14:13 INFO: Detected a machine on IP address 10.11.193.1 which has 856 cores and 120.0 links\n",
      "2023-07-03 10:14:13 INFO: Machine generator took 0:00:09.947168 \n",
      "2023-07-03 10:14:13 INFO: Json machine skipped as cfg Reports:write_json_machine is False\n",
      "Writing the board chip report\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:14:13 INFO: Board chip report took 0:00:00.011860 \n",
      "Adding commands\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:14:13 INFO: Command Sender Adder took 0:00:00.011583 \n",
      "2023-07-03 10:14:13 INFO: Split Live Gather Vertices took 0:00:00.000015 \n",
      "Adding Chip power monitors to Graph\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:14:13 INFO: Insert chip power monitors took 0:00:00.037430 \n",
      "2023-07-03 10:14:13 INFO: Insert extra monitor vertices took 0:00:00.000020 \n",
      "Inserting extra monitors into graphs\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Generating partitioner report\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:14:13 INFO: Partitioner report took 0:00:00.012956 \n",
      "2023-07-03 10:14:13 INFO: Local TDMA builder took 0:00:00.000111 \n",
      "Placing Vertices\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:14:13 INFO: Application Placer took 0:00:00.078929 \n",
      "Generating placement report\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Generating placement by core report\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:14:14 INFO: Placements wth application graph report took 0:00:00.113764 \n",
      "2023-07-03 10:14:14 INFO: Json placements skipped as cfg Reports:write_json_placements is False\n",
      "Generating routing tables for data in system processes\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:14:14 INFO: System multicast routing generator took 0:00:00.011959 \n",
      "Generating fixed router routes\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:14:14 INFO: Fixed route router took 0:00:00.010548 \n",
      "Routing\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:14:14 INFO: Application Router took 0:00:00.012450 \n",
      "Allocating tags\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:14:14 INFO: Basic tag allocator took 0:00:00.053397 \n",
      "Reporting Tags\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:14:14 INFO: Tag allocator report took 0:00:00.010396 \n",
      "Calculating zones\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Allocating routing keys\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:14:14 INFO: Zoned routing info allocator took 0:00:00.021982 \n",
      "Generating Routing info report\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "\n",
      "2023-07-03 10:14:14 INFO: Router info report took 0:00:00.011986 \n",
      "Generating routing tables\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:14:14 INFO: Merged routing table generator took 0:00:00.010888 \n",
      "Generating Router table report\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:14:14 INFO: Uncompressed routing table report took 0:00:00.010736 \n",
      "2023-07-03 10:14:14 INFO: Router report skipped as cfg Reports:write_router_reports is False\n",
      "2023-07-03 10:14:14 INFO: Router summary report skipped as cfg Reports:write_router_summary_report is False\n",
      "2023-07-03 10:14:14 INFO: Json routing tables skipped as cfg Reports:write_json_routing_tables is False\n",
      "2023-07-03 10:14:14 INFO: Locate executable start type took 0:00:00.000403 \n",
      "2023-07-03 10:14:14 INFO: Buffer manager creator took 0:00:00.001446 \n",
      "2023-07-03 10:14:14 INFO: Write Neo Metadata took 0:00:00.014896 \n",
      "2023-07-03 10:14:14 INFO: Record vertex labels to database took 0:00:00.002156 \n",
      "Preparing Routing Tables\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:14:14 INFO: Routing setup took 0:00:00.021093 \n",
      "Finding binaries\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:14:14 INFO: Graph binary gatherer took 0:00:00.071077 \n",
      "2023-07-03 10:14:14 INFO: Pair on chip router compression skipped as Tables already small enough\n",
      "Allocating SDRAM for SDRAM outgoing egde partitions\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:14:14 INFO: SDRAM outgoing partition allocator took 0:00:00.014642 \n",
      "Generating data specifications\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:14:19 INFO: Graph data specification writer took 0:00:05.343796 \n",
      "2023-07-03 10:14:19 INFO: Control Sync took 0:00:00.000675 \n",
      "loading fixed routes\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:14:19 INFO: Load fixed routes took 0:00:00.053662 \n",
      "Executing data specifications and loading data for system vertices using Java\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:14:21 INFO: Execute system data specification took 0:00:01.768736 \n",
      "Loading system executables onto the machine\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:14:21 INFO: Load executable system Images took 0:00:00.289062 \n",
      "Clearing tags\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Loading Tags\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:14:21 INFO: Tags Loader took 0:00:00.031551 \n",
      "Executing data specifications and loading data for application vertices using Java\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:14:26 INFO: Host data specification took 0:00:04.946019 \n",
      "Preparing to Expand Neuron Data\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Expanding Neuron Data\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "\n",
      "\n",
      "Getting initial values\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:14:27 INFO: Neuron expander took 0:00:00.917960 \n",
      "Preparing to Expand Synapses\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Expanding Synapses\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "\n",
      "\n",
      "2023-07-03 10:14:28 INFO: Synapse expander took 0:00:01.060675 \n",
      "Finalising Retrieved Connections\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:14:28 INFO: Finish connection holders took 0:00:00.014507 \n",
      "Loading routing data onto the machine\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:14:28 INFO: Routing table loader took 0:00:00.015521 \n",
      "2023-07-03 10:14:28 INFO: Bitfield compressor report skipped as cfg Reports:write_bit_field_compressor_report is False\n",
      "2023-07-03 10:14:28 INFO: Tags from machine report took 0:00:00.003216 \n",
      "2023-07-03 10:14:28 INFO: Memory report skipped as cfg Reports:write_memory_map_report is False\n",
      "2023-07-03 10:14:28 INFO: Memory report skipped as cfg Reports:write_memory_map_report is False\n",
      "Generating compressed router table report\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Generating comparison of router table report\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Generating Routing summary report\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Reading Routing Tables from Machine\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:14:29 INFO: Compressor report took 0:00:00.080657 \n",
      "Writing fixed route report\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:14:29 INFO: Fixed route report took 0:00:00.056073 \n",
      "Loading executables onto the machine\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:14:29 INFO: Load executable app images took 0:00:00.605998 \n",
      "2023-07-03 10:14:29 INFO: Running for 3 steps for a total of 141364.0ms\n",
      "2023-07-03 10:14:29 INFO: Run 1 of 3\n",
      "Generating SDRAM usage report\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:14:29 INFO: Sdram usage per chip report took 0:00:00.236384 \n",
      "2023-07-03 10:14:29 INFO: Drift report skipped as cfg Reports:write_drift_report_start is False\n",
      "2023-07-03 10:14:29 INFO: Creating live event connection database in /home/bbpnrsoa/FromSep2022/VoltageAsRateCodingForClassification/APROVIS3D/only_weights_plot_and_analysis/toPushOnGithub/reports/2023-07-03-10-13-53-182379/run_1/input_output_database.sqlite3\n",
      "Creating graph description database\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:14:30 INFO: Create database interface took 0:00:00.040478 \n",
      "2023-07-03 10:14:30 INFO: Create notification protocol took 0:00:00.000764 \n",
      "Waiting for cores to be either in PAUSED or READY state\n",
      "|0%                          50%                         100%|\n",
      " 2023-07-03 10:14:30 INFO: ** Notifying external sources that the database is ready for reading **\n",
      "============================================================\n",
      "Updating run time\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:14:30 INFO: Runtime Update took 0:00:00.091495 \n",
      "2023-07-03 10:14:30 INFO: *** Running simulation... *** \n",
      "Loading buffers\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:15:00 INFO: ** Awaiting for a response from an external source to state its ready for the simulation to start **\n",
      "2023-07-03 10:15:00 INFO: ** Sending start / resume message to external sources to state the simulation has started or resumed. **\n",
      "2023-07-03 10:15:00 INFO: ** Awaiting for a response from an external source to state its ready for the simulation to start **\n",
      "2023-07-03 10:15:00 INFO: Application started; waiting 63.469s for it to stop\n",
      "2023-07-03 10:16:04 INFO: ** Sending pause / stop message to external sources to state the simulation has been paused or stopped. **\n",
      "2023-07-03 10:16:04 INFO: Application runner took 0:01:34.148727 \n",
      "2023-07-03 10:16:04 INFO: Extract IO buff skipped as cfg Reports:extract_iobuf is False\n",
      "2023-07-03 10:16:04 INFO: Starting buffer extraction using Java\n",
      "2023-07-03 10:16:44 INFO: Buffer extractor took 0:00:39.795192 \n",
      "clearing IOBUF from the machine\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:16:44 INFO: Clear IO buffer took 0:00:00.063865 \n",
      "Getting provenance data from application graph\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:16:44 INFO: Graph provenance gatherer took 0:00:00.016652 \n",
      "Getting provenance data\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:16:44 INFO: Placements provenance gatherer took 0:00:00.286783 \n",
      "Getting Router Provenance\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:16:44 INFO: Router provenance gatherer took 0:00:00.240867 \n",
      "Getting profile data\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:16:44 INFO: Profile data gatherer took 0:00:00.081544 \n",
      "2023-07-03 10:17:17 INFO: Energy report took 0:00:32.970160 \n",
      "2023-07-03 10:17:17 INFO: Redundant packet count report took 0:00:00.014460 \n",
      "2023-07-03 10:17:17 INFO: Drift report skipped as cfg Reports:write_drift_report_end is False\n",
      "2023-07-03 10:17:17 INFO: Control Sync took 0:00:00.000745 \n",
      "2023-07-03 10:17:17 INFO: Run 2 of 3\n",
      "Generating SDRAM usage report\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:17:18 INFO: Sdram usage per chip report took 0:00:00.240640 \n",
      "2023-07-03 10:17:18 INFO: Drift report skipped as cfg Reports:write_drift_report_start is False\n",
      "2023-07-03 10:17:18 INFO: Creating live event connection database in /home/bbpnrsoa/FromSep2022/VoltageAsRateCodingForClassification/APROVIS3D/only_weights_plot_and_analysis/toPushOnGithub/reports/2023-07-03-10-13-53-182379/run_1/input_output_database.sqlite3\n",
      "Creating graph description database\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:17:18 INFO: Create database interface took 0:00:00.041175 \n",
      "2023-07-03 10:17:18 INFO: Create notification protocol took 0:00:00.000776 \n",
      "Waiting for cores to be either in PAUSED or READY state\n",
      "|0%                          50%                         100%|\n",
      " 2023-07-03 10:17:18 INFO: ** Notifying external sources that the database is ready for reading **\n",
      "============================================================\n",
      "Updating run time\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:17:18 INFO: Runtime Update took 0:00:00.111260 \n",
      "2023-07-03 10:17:18 INFO: *** Running simulation... *** \n",
      "Loading buffers\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:17:49 INFO: ** Awaiting for a response from an external source to state its ready for the simulation to start **\n",
      "2023-07-03 10:17:49 INFO: ** Sending start / resume message to external sources to state the simulation has started or resumed. **\n",
      "2023-07-03 10:17:49 INFO: ** Awaiting for a response from an external source to state its ready for the simulation to start **\n",
      "2023-07-03 10:17:49 INFO: Application started; waiting 63.469s for it to stop\n",
      "2023-07-03 10:18:53 INFO: ** Sending pause / stop message to external sources to state the simulation has been paused or stopped. **\n",
      "2023-07-03 10:18:53 INFO: Application runner took 0:01:35.223049 \n",
      "2023-07-03 10:18:53 INFO: Extract IO buff skipped as cfg Reports:extract_iobuf is False\n",
      "2023-07-03 10:18:53 INFO: Starting buffer extraction using Java\n",
      "2023-07-03 10:19:33 INFO: Buffer extractor took 0:00:40.126584 \n",
      "clearing IOBUF from the machine\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:19:33 INFO: Clear IO buffer took 0:00:00.054065 \n",
      "Getting provenance data from application graph\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:19:33 INFO: Graph provenance gatherer took 0:00:00.016368 \n",
      "Getting provenance data\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:19:33 INFO: Placements provenance gatherer took 0:00:00.271143 \n",
      "Getting Router Provenance\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:19:34 INFO: Router provenance gatherer took 0:00:00.245946 \n",
      "Getting profile data\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:19:34 INFO: Profile data gatherer took 0:00:00.065868 \n",
      "2023-07-03 10:20:37 INFO: Energy report took 0:01:03.420606 \n",
      "2023-07-03 10:20:37 INFO: Redundant packet count report took 0:00:00.025372 \n",
      "2023-07-03 10:20:37 INFO: Drift report skipped as cfg Reports:write_drift_report_end is False\n",
      "2023-07-03 10:20:37 INFO: Control Sync took 0:00:00.000619 \n",
      "2023-07-03 10:20:37 INFO: Run 3 of 3\n",
      "Generating SDRAM usage report\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:20:37 INFO: Sdram usage per chip report took 0:00:00.232209 \n",
      "2023-07-03 10:20:37 INFO: Drift report skipped as cfg Reports:write_drift_report_start is False\n",
      "2023-07-03 10:20:37 INFO: Creating live event connection database in /home/bbpnrsoa/FromSep2022/VoltageAsRateCodingForClassification/APROVIS3D/only_weights_plot_and_analysis/toPushOnGithub/reports/2023-07-03-10-13-53-182379/run_1/input_output_database.sqlite3\n",
      "Creating graph description database\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:20:37 INFO: Create database interface took 0:00:00.041623 \n",
      "2023-07-03 10:20:37 INFO: ** Notifying external sources that the database is ready for reading **\n",
      "2023-07-03 10:20:37 INFO: Create notification protocol took 0:00:00.000825 \n",
      "Waiting for cores to be either in PAUSED or READY state\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "Updating run time\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:20:38 INFO: Runtime Update took 0:00:00.103752 \n",
      "2023-07-03 10:20:38 INFO: *** Running simulation... *** \n",
      "Loading buffers\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:20:42 INFO: ** Awaiting for a response from an external source to state its ready for the simulation to start **\n",
      "2023-07-03 10:20:42 INFO: ** Sending start / resume message to external sources to state the simulation has started or resumed. **\n",
      "2023-07-03 10:20:42 INFO: ** Awaiting for a response from an external source to state its ready for the simulation to start **\n",
      "2023-07-03 10:20:42 INFO: Application started; waiting 14.725999999999999s for it to stop\n",
      "2023-07-03 10:20:56 INFO: ** Sending pause / stop message to external sources to state the simulation has been paused or stopped. **\n",
      "2023-07-03 10:20:56 INFO: Application runner took 0:00:18.852044 \n",
      "2023-07-03 10:20:56 INFO: Extract IO buff skipped as cfg Reports:extract_iobuf is False\n",
      "2023-07-03 10:20:56 INFO: Starting buffer extraction using Java\n",
      "2023-07-03 10:21:07 INFO: Buffer extractor took 0:00:10.215827 \n",
      "clearing IOBUF from the machine\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:21:07 INFO: Clear IO buffer took 0:00:00.052494 \n",
      "Getting provenance data from application graph\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:21:07 INFO: Graph provenance gatherer took 0:00:00.015383 \n",
      "Getting provenance data\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:21:07 INFO: Placements provenance gatherer took 0:00:00.261054 \n",
      "Getting Router Provenance\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:21:07 INFO: Router provenance gatherer took 0:00:00.254555 \n",
      "Getting profile data\n",
      "|0%                          50%                         100%|\n",
      " ============================================================\n",
      "2023-07-03 10:21:07 INFO: Profile data gatherer took 0:00:00.063679 \n",
      "2023-07-03 10:22:17 INFO: Energy report took 0:01:10.165359 \n",
      "2023-07-03 10:22:17 INFO: Redundant packet count report took 0:00:00.036938 \n",
      "2023-07-03 10:22:17 INFO: Drift report skipped as cfg Reports:write_drift_report_end is False\n",
      "2023-07-03 10:22:17 INFO: Control Sync took 0:00:00.000742 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "141364.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyNN.spiNNaker as p\n",
    "import pyNN.utility.plotting as plot\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "p.setup(1.0)\n",
    "\n",
    "ssa = p.Population(RETINA_DIM*RETINA_DIM*P_NUM, p.SpikeSourceArray(spike_times=SSA_as_output_for_test))\n",
    "\n",
    "pop_xy = p.Population(X_NUM*Y_NUM*P_NUM,\n",
    "                      p.IF_curr_exp,\n",
    "                      label = 'pop_xy')\n",
    "\n",
    "pop_out = p.Population(512,\n",
    "                          p.IF_curr_exp,\n",
    "                          label = 'pop_out')\n",
    "\n",
    "\n",
    "ssa.record(['spikes'])\n",
    "pop_xy.record(['spikes'])\n",
    "pop_out.record(['spikes'])\n",
    "\n",
    "p.Projection(ssa, \n",
    "             pop_xy, \n",
    "             p.FromListConnector(connections_ssa_xy),\n",
    "             p.StaticSynapse())\n",
    "\n",
    "connections_list_from_file=p.FromFileConnector('ConnectionFile_w_fc1_2048_512_32_32_ANN_BCE_One_Layer_84_testAccuracy.txt')\n",
    "\n",
    "xy_out_prj = p.Projection(pop_xy, \n",
    "             pop_out, \n",
    "             connections_list_from_file,\n",
    "             p.StaticSynapse())\n",
    "\n",
    "\n",
    "\n",
    "#######################################################################################################\n",
    "simtime = time\n",
    "p.run(simtime)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2ea9d9-e46b-4da7-8b3f-eb3533495ee2",
   "metadata": {},
   "source": [
    "## Extracting the output spikeTrains (per output neurons) and using the `count_output_spikes_per_inputs` function for counting the number of generated spikes per each input samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74c0e7a7-6137-49ca-a871-cb231b0cd223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "output_size = 1\n",
    "output_spike_trains=[pop_out.get_data(\"spikes\").segments[0].spiketrains[i][:] for i in range(output_size)]\n",
    "# count_output_spikes_per_inputs(spikeTrain=output_spike_trains, number_of_input_data= len(testloader), total_synaptic_delay=1, timesteps=1, number_of_steps=data_lenght, inputs_interval=5000)\n",
    "data_lenght = 1000 # time_window = 100 mSec\n",
    "output_spike_count_matrix = count_output_spikes_per_inputs(spikeTrain=output_spike_trains, number_of_input_data= len(testloader), total_synaptic_delay=1, timesteps=1, number_of_steps=data_lenght, inputs_interval=0)\n",
    "# timesteps=1, number_of_steps=1e6 considering the time_window in daraset to have the correct lenght of each input\n",
    "# sample_interval in uSeconds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99a923b4-d273-4ca3-995c-61d00ea957c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label: 1, prediction: 1, number of spikes: 88.0\n",
      "True label: 0, prediction: 0, number of spikes: 0.0\n",
      "True label: 1, prediction: 1, number of spikes: 254.0\n",
      "True label: 1, prediction: 1, number of spikes: 1.0\n",
      "True label: 0, prediction: 0, number of spikes: 0.0\n",
      "True label: 1, prediction: 1, number of spikes: 105.0\n",
      "True label: 1, prediction: 1, number of spikes: 165.0\n",
      "True label: 0, prediction: 0, number of spikes: 0.0\n",
      "True label: 0, prediction: 1, number of spikes: 2.0\n",
      "True label: 1, prediction: 1, number of spikes: 166.0\n",
      "True label: 0, prediction: 0, number of spikes: 0.0\n",
      "True label: 0, prediction: 0, number of spikes: 0.0\n",
      "True label: 0, prediction: 1, number of spikes: 2.0\n",
      "True label: 1, prediction: 1, number of spikes: 76.0\n",
      "True label: 1, prediction: 1, number of spikes: 96.0\n",
      "True label: 1, prediction: 1, number of spikes: 254.0\n",
      "True label: 0, prediction: 1, number of spikes: 1.0\n",
      "True label: 0, prediction: 1, number of spikes: 54.0\n",
      "True label: 1, prediction: 1, number of spikes: 73.0\n",
      "True label: 1, prediction: 1, number of spikes: 95.0\n",
      "True label: 1, prediction: 1, number of spikes: 147.0\n",
      "True label: 0, prediction: 1, number of spikes: 2.0\n",
      "True label: 0, prediction: 0, number of spikes: 0.0\n",
      "True label: 0, prediction: 1, number of spikes: 2.0\n",
      "True label: 1, prediction: 1, number of spikes: 35.0\n",
      "True label: 1, prediction: 0, number of spikes: 0.0\n",
      "True label: 0, prediction: 1, number of spikes: 3.0\n",
      "True label: 1, prediction: 0, number of spikes: 0.0\n",
      "True label: 0, prediction: 1, number of spikes: 6.0\n",
      "True label: 0, prediction: 1, number of spikes: 106.0\n",
      "True label: 1, prediction: 1, number of spikes: 162.0\n",
      "True label: 0, prediction: 0, number of spikes: 0.0\n",
      "True label: 0, prediction: 1, number of spikes: 4.0\n",
      "True label: 1, prediction: 1, number of spikes: 67.0\n",
      "True label: 0, prediction: 0, number of spikes: 0.0\n",
      "True label: 0, prediction: 0, number of spikes: 0.0\n",
      "True label: 0, prediction: 0, number of spikes: 0.0\n",
      "True label: 1, prediction: 0, number of spikes: 0.0\n",
      "True label: 0, prediction: 0, number of spikes: 0.0\n",
      "True label: 0, prediction: 1, number of spikes: 2.0\n",
      "True label: 0, prediction: 1, number of spikes: 29.0\n",
      "True label: 0, prediction: 1, number of spikes: 26.0\n",
      "True label: 0, prediction: 1, number of spikes: 146.0\n",
      "True label: 0, prediction: 0, number of spikes: 0.0\n",
      "True label: 0, prediction: 1, number of spikes: 16.0\n",
      "True label: 1, prediction: 1, number of spikes: 93.0\n",
      "True label: 0, prediction: 1, number of spikes: 10.0\n",
      "True label: 0, prediction: 0, number of spikes: 0.0\n",
      "True label: 1, prediction: 0, number of spikes: 0.0\n",
      "True label: 1, prediction: 0, number of spikes: 0.0\n",
      "True label: 0, prediction: 1, number of spikes: 5.0\n",
      "True label: 0, prediction: 0, number of spikes: 0.0\n",
      "True label: 0, prediction: 1, number of spikes: 43.0\n",
      "True label: 1, prediction: 1, number of spikes: 71.0\n",
      "True label: 0, prediction: 1, number of spikes: 73.0\n",
      "True label: 1, prediction: 1, number of spikes: 99.0\n",
      "True label: 0, prediction: 1, number of spikes: 18.0\n",
      "True label: 0, prediction: 0, number of spikes: 0.0\n",
      "True label: 1, prediction: 1, number of spikes: 28.0\n",
      "True label: 1, prediction: 1, number of spikes: 23.0\n",
      "True label: 0, prediction: 0, number of spikes: 0.0\n",
      "True label: 0, prediction: 1, number of spikes: 1.0\n",
      "True label: 0, prediction: 1, number of spikes: 11.0\n",
      "True label: 0, prediction: 1, number of spikes: 18.0\n",
      "True label: 0, prediction: 0, number of spikes: 0.0\n",
      "True label: 0, prediction: 1, number of spikes: 71.0\n",
      "True label: 1, prediction: 1, number of spikes: 79.0\n",
      "True label: 0, prediction: 1, number of spikes: 40.0\n",
      "True label: 1, prediction: 1, number of spikes: 45.0\n",
      "True label: 1, prediction: 0, number of spikes: 0.0\n",
      "True label: 0, prediction: 0, number of spikes: 0.0\n",
      "True label: 0, prediction: 1, number of spikes: 20.0\n",
      "True label: 0, prediction: 1, number of spikes: 43.0\n",
      "True label: 0, prediction: 0, number of spikes: 0.0\n",
      "True label: 1, prediction: 1, number of spikes: 1.0\n",
      "True label: 0, prediction: 1, number of spikes: 24.0\n",
      "True label: 1, prediction: 1, number of spikes: 58.0\n",
      "True label: 0, prediction: 1, number of spikes: 96.0\n",
      "True label: 1, prediction: 1, number of spikes: 92.0\n",
      "True label: 1, prediction: 1, number of spikes: 99.0\n",
      "True label: 1, prediction: 1, number of spikes: 160.0\n",
      "True label: 1, prediction: 1, number of spikes: 50.0\n",
      "True label: 0, prediction: 0, number of spikes: 0.0\n",
      "True label: 1, prediction: 1, number of spikes: 62.0\n",
      "True label: 1, prediction: 1, number of spikes: 92.0\n",
      "True label: 1, prediction: 1, number of spikes: 15.0\n",
      "True label: 0, prediction: 1, number of spikes: 8.0\n",
      "True label: 0, prediction: 1, number of spikes: 9.0\n",
      "True label: 0, prediction: 1, number of spikes: 67.0\n",
      "True label: 1, prediction: 1, number of spikes: 147.0\n",
      "True label: 1, prediction: 1, number of spikes: 149.0\n",
      "True label: 1, prediction: 1, number of spikes: 89.0\n",
      "True label: 0, prediction: 1, number of spikes: 29.0\n",
      "True label: 1, prediction: 1, number of spikes: 15.0\n",
      "True label: 0, prediction: 1, number of spikes: 37.0\n",
      "True label: 1, prediction: 1, number of spikes: 75.0\n",
      "True label: 0, prediction: 1, number of spikes: 10.0\n",
      "True label: 1, prediction: 0, number of spikes: 0.0\n",
      "True label: 0, prediction: 0, number of spikes: 0.0\n",
      "True label: 0, prediction: 1, number of spikes: 25.0\n",
      "True label: 1, prediction: 1, number of spikes: 145.0\n",
      "True label: 1, prediction: 1, number of spikes: 204.0\n",
      "True label: 1, prediction: 1, number of spikes: 72.0\n",
      "True label: 0, prediction: 1, number of spikes: 35.0\n",
      "True label: 1, prediction: 1, number of spikes: 126.0\n",
      "True label: 1, prediction: 1, number of spikes: 93.0\n",
      "True label: 1, prediction: 0, number of spikes: 0.0\n",
      "True label: 0, prediction: 0, number of spikes: 0.0\n",
      "True label: 0, prediction: 1, number of spikes: 76.0\n",
      "True label: 1, prediction: 1, number of spikes: 65.0\n",
      "True label: 0, prediction: 0, number of spikes: 0.0\n",
      "True label: 0, prediction: 0, number of spikes: 0.0\n",
      "True label: 0, prediction: 1, number of spikes: 45.0\n",
      "True label: 1, prediction: 1, number of spikes: 91.0\n",
      "True label: 1, prediction: 1, number of spikes: 89.0\n",
      "True label: 1, prediction: 0, number of spikes: 0.0\n",
      "True label: 0, prediction: 1, number of spikes: 13.0\n",
      "True label: 0, prediction: 0, number of spikes: 0.0\n",
      "True label: 1, prediction: 0, number of spikes: 0.0\n",
      "True label: 0, prediction: 1, number of spikes: 62.0\n",
      "True label: 1, prediction: 1, number of spikes: 47.0\n",
      "True label: 0, prediction: 0, number of spikes: 0.0\n",
      "True label: 1, prediction: 0, number of spikes: 0.0\n",
      "True label: 0, prediction: 0, number of spikes: 0.0\n",
      "True label: 0, prediction: 0, number of spikes: 0.0\n",
      "True label: 0, prediction: 1, number of spikes: 105.0\n",
      "True label: 1, prediction: 1, number of spikes: 55.0\n",
      "True label: 0, prediction: 0, number of spikes: 0.0\n",
      "True label: 0, prediction: 0, number of spikes: 0.0\n",
      "True label: 0, prediction: 0, number of spikes: 0.0\n",
      "True label: 1, prediction: 0, number of spikes: 0.0\n",
      "True label: 0, prediction: 1, number of spikes: 72.0\n",
      "True label: 1, prediction: 1, number of spikes: 128.0\n",
      "True label: 1, prediction: 1, number of spikes: 50.0\n",
      "True label: 0, prediction: 1, number of spikes: 10.0\n",
      "True label: 0, prediction: 1, number of spikes: 23.0\n",
      "True label: 0, prediction: 1, number of spikes: 54.0\n",
      "True label: 1, prediction: 1, number of spikes: 31.0\n",
      "True label: 0, prediction: 0, number of spikes: 0.0\n",
      "True label: 1, prediction: 0, number of spikes: 0.0\n",
      "True label: 0, prediction: 0, number of spikes: 0.0\n",
      "True label: 0, prediction: 0, number of spikes: 0.0\n"
     ]
    }
   ],
   "source": [
    "threshold = 0\n",
    "for i in range(len(testloader)):\n",
    "    print(f'True label: {targets[i].item()}, prediction: {int(output_spike_count_matrix[0][i]>threshold)}, number of spikes: {output_spike_count_matrix[0][i].item()}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b367b111-4f52-4de5-89ce-723133a463a0",
   "metadata": {},
   "source": [
    "## Check accuracy for BCE: it will only have output when the input is peridicted as `land` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4fe4ce6-1be3-4da2-a2c1-d98d6e29af4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "         True,  True, False,  True,  True,  True, False, False,  True,  True,\n",
       "         True, False,  True, False,  True, False, False, False, False, False,\n",
       "         True,  True, False,  True,  True,  True,  True, False,  True, False,\n",
       "        False, False, False,  True, False,  True, False,  True, False, False,\n",
       "        False,  True, False,  True, False,  True, False,  True,  True,  True,\n",
       "         True, False, False, False,  True, False,  True, False,  True, False,\n",
       "         True, False, False,  True,  True, False,  True, False,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True, False, False, False,  True,\n",
       "         True,  True, False,  True, False,  True, False, False,  True, False,\n",
       "         True,  True,  True, False,  True,  True, False,  True, False,  True,\n",
       "         True,  True, False,  True,  True, False, False,  True, False, False,\n",
       "         True,  True, False,  True,  True, False,  True,  True,  True,  True,\n",
       "        False, False,  True,  True, False, False, False,  True,  True, False,\n",
       "         True,  True])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((output_spike_count_matrix[0]>0).to(int)==torch.tensor(targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319ef2ca-c6d9-4713-9049-4fde90968132",
   "metadata": {},
   "source": [
    "## We can deifine a threshold for the `number of output spikes` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae59f427-f568-4d85-a6fa-151576e0f9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 142 test with threshold = 0: 58.45070266723633 %\n",
      "Accuracy of the network on the 142 test with threshold = 10: 68.30986022949219 %\n",
      "Accuracy of the network on the 142 test with threshold = 20: 71.12676239013672 %\n",
      "Accuracy of the network on the 142 test with threshold = 30: 73.94366455078125 %\n",
      "Accuracy of the network on the 142 test with threshold = 40: 74.64788818359375 %\n",
      "Accuracy of the network on the 142 test with threshold = 50: 73.94366455078125 %\n",
      "Accuracy of the network on the 142 test with threshold = 60: 73.94366455078125 %\n",
      "Accuracy of the network on the 142 test with threshold = 70: 73.23943328857422 %\n",
      "Accuracy of the network on the 142 test with threshold = 80: 71.83098602294922 %\n",
      "Accuracy of the network on the 142 test with threshold = 90: 69.71830749511719 %\n",
      "Accuracy of the network on the 142 test with threshold = 100: 64.08451080322266 %\n"
     ]
    }
   ],
   "source": [
    "n_input_samples = len(testloader)\n",
    "thresholds = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "for threshold in thresholds:\n",
    "    n_correct = sum((output_spike_count_matrix[0]>threshold).to(int)==torch.tensor(targets))\n",
    "    acc = 100.0 * n_correct / n_input_samples\n",
    "    print(f'Accuracy of the network on the {n_input_samples} test with threshold = {threshold}: {acc} %')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sPyNNakerGit",
   "language": "python",
   "name": "spynnakergit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
